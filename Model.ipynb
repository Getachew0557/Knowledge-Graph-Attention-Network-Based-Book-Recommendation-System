{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42cb3bc3",
   "metadata": {},
   "source": [
    "# Implementing a Knowledge Graph Attention Network (KGAT) for Book Recommendations\n",
    "This guide will walk you through implementing a Knowledge Graph Attention Network (KGAT) for building a book recommendation system. KGAT is a state-of-the-art recommendation approach that combines knowledge graphs with graph attention networks to provide more accurate and explainable recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dcc499",
   "metadata": {},
   "source": [
    "## Understanding KGAT\n",
    "Knowledge Graph Attention Network (KGAT) is a hybrid model that:\n",
    "\n",
    "- Incorporates knowledge graphs to represent rich semantic relationships\n",
    "\n",
    "- Uses graph attention networks to learn importance weights between nodes\n",
    "\n",
    "- Captures high-order connectivity in the knowledge graph\n",
    "\n",
    "- The key components are:\n",
    "\n",
    "  - Entity embedding: Represents books, users, and other entities\n",
    "\n",
    "   - Relation embedding: Represents different types of relationships\n",
    "\n",
    "- Attention mechanism: Learns importance weights between connected nodes\n",
    "\n",
    "## Dataset Preparation\n",
    "We'll use the Book-Crossing dataset which contains:\n",
    "\n",
    "- Book information (title, author, year, publisher)\n",
    "\n",
    "- User information (location, age)\n",
    "\n",
    "- Ratings (explicit ratings 1-10)\n",
    "\n",
    "First, let's preprocess the data similarly to your original code but extend it for KGAT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce73d9d",
   "metadata": {},
   "source": [
    "# Step 1: Load and Preprocess Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c481f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1044d4e1",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bbe8720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading datasets...\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 1: Loading datasets...\")\n",
    "# Specify dtypes to handle mixed types in 'Year-Of-Publication'\n",
    "books_dtypes = {\n",
    "    'ISBN': str,\n",
    "    'Book-Title': str,\n",
    "    'Book-Author': str,\n",
    "    'Year-Of-Publication': str,  # Load as string to handle mixed types\n",
    "    'Publisher': str,\n",
    "    'Image-URL-S': str,\n",
    "    'Image-URL-M': str,\n",
    "    'Image-URL-L': str\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9680649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading datasets...\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and Preprocess Datasets\n",
    "print(\"Step 1: Loading datasets...\")\n",
    "# Specify dtypes to handle mixed types in 'Year-Of-Publication'\n",
    "books = pd.read_csv('data/BX-Books.csv', sep=';', encoding='latin-1', on_bad_lines='skip', dtype=books_dtypes)\n",
    "users = pd.read_csv('data/BX-Users.csv', sep=';', encoding='latin-1', on_bad_lines='skip')\n",
    "ratings = pd.read_csv('data/BX-Book-Ratings.csv', sep=';', encoding='latin-1', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12a19ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65421635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271360, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40033507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID                            Location   Age\n",
       "0        1                  nyc, new york, usa   NaN\n",
       "1        2           stockton, california, usa  18.0\n",
       "2        3     moscow, yukon territory, russia   NaN\n",
       "3        4           porto, v.n.gaia, portugal  17.0\n",
       "4        5  farnborough, hants, united kingdom   NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ed2dbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278858, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d2ff7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "580e7680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(526356, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7feea1",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff93671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'Year-Of-Publication' by converting to numeric, setting invalid values to NaN\n",
    "books['Year-Of-Publication'] = pd.to_numeric(books['Year-Of-Publication'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8cc3f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books DataFrame head:\n",
      "         ISBN                                              title  \\\n",
      "0  0195153448                                Classical Mythology   \n",
      "1  0002005018                                       Clara Callan   \n",
      "2  0060973129                               Decision in Normandy   \n",
      "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
      "4  0393045218                             The Mummies of Urumchi   \n",
      "\n",
      "                 author    year                   publisher  \n",
      "0    Mark P. O. Morford  2002.0     Oxford University Press  \n",
      "1  Richard Bruce Wright  2001.0       HarperFlamingo Canada  \n",
      "2          Carlo D'Este  1991.0             HarperPerennial  \n",
      "3      Gina Bari Kolata  1999.0        Farrar Straus Giroux  \n",
      "4       E. J. W. Barber  1999.0  W. W. Norton &amp; Company  \n",
      "\n",
      "Users DataFrame head:\n",
      "   user_id                            location   age\n",
      "0        1                  nyc, new york, usa   NaN\n",
      "1        2           stockton, california, usa  18.0\n",
      "2        3     moscow, yukon territory, russia   NaN\n",
      "3        4           porto, v.n.gaia, portugal  17.0\n",
      "4        5  farnborough, hants, united kingdom   NaN\n",
      "\n",
      "Ratings DataFrame head:\n",
      "   user_id        ISBN  rating\n",
      "0   276725  034545104X       0\n",
      "1   276726  0155061224       5\n",
      "2   276727  0446520802       0\n",
      "3   276729  052165615X       3\n",
      "4   276729  0521795028       6\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns and rename\n",
    "books = books[['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher']]\n",
    "books.rename(columns={\n",
    "    'Book-Title': 'title',\n",
    "    'Book-Author': 'author',\n",
    "    'Year-Of-Publication': 'year',\n",
    "    'Publisher': 'publisher'\n",
    "}, inplace=True)\n",
    "\n",
    "users.rename(columns={\n",
    "    'User-ID': 'user_id',\n",
    "    'Location': 'location',\n",
    "    'Age': 'age'\n",
    "}, inplace=True)\n",
    "\n",
    "ratings.rename(columns={\n",
    "    'User-ID': 'user_id',\n",
    "    'Book-Rating': 'rating'\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"Books DataFrame head:\")\n",
    "print(books.head())\n",
    "print(\"\\nUsers DataFrame head:\")\n",
    "print(users.head())\n",
    "print(\"\\nRatings DataFrame head:\")\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0435b",
   "metadata": {},
   "source": [
    "## Step 2: Filter Active Users and Popular Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cd352bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Filtering active users and popular books...\n",
      "Number of active users: 899\n"
     ]
    }
   ],
   "source": [
    "#  Filter Active Users and Popular Books\n",
    "print(\"\\nStep 2: Filtering active users and popular books...\")\n",
    "# Filter users who rated at least 200 books\n",
    "user_counts = ratings['user_id'].value_counts()\n",
    "active_users = user_counts[user_counts > 200].index\n",
    "ratings = ratings[ratings['user_id'].isin(active_users)]\n",
    "print(f\"Number of active users: {len(active_users)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b1f25b",
   "metadata": {},
   "source": [
    "## Merge ratings with books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2888f30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings with books merged DataFrame head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277427</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>277427</td>\n",
       "      <td>0026217457</td>\n",
       "      <td>0</td>\n",
       "      <td>Vegetarian Times Complete Cookbook</td>\n",
       "      <td>Lucy  Moll</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>John Wiley &amp;amp; Sons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>277427</td>\n",
       "      <td>003008685X</td>\n",
       "      <td>8</td>\n",
       "      <td>Pioneers</td>\n",
       "      <td>James Fenimore Cooper</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>Thomson Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>277427</td>\n",
       "      <td>0030615321</td>\n",
       "      <td>0</td>\n",
       "      <td>Ask for May, Settle for June (A Doonesbury book)</td>\n",
       "      <td>G. B. Trudeau</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>Henry Holt &amp;amp; Co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>277427</td>\n",
       "      <td>0060002050</td>\n",
       "      <td>0</td>\n",
       "      <td>On a Wicked Dawn (Cynster Novels)</td>\n",
       "      <td>Stephanie Laurens</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Avon Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        ISBN  rating  \\\n",
       "0   277427  002542730X      10   \n",
       "1   277427  0026217457       0   \n",
       "2   277427  003008685X       8   \n",
       "3   277427  0030615321       0   \n",
       "4   277427  0060002050       0   \n",
       "\n",
       "                                               title                 author  \\\n",
       "0  Politically Correct Bedtime Stories: Modern Ta...      James Finn Garner   \n",
       "1                 Vegetarian Times Complete Cookbook             Lucy  Moll   \n",
       "2                                           Pioneers  James Fenimore Cooper   \n",
       "3   Ask for May, Settle for June (A Doonesbury book)          G. B. Trudeau   \n",
       "4                  On a Wicked Dawn (Cynster Novels)      Stephanie Laurens   \n",
       "\n",
       "     year                  publisher  \n",
       "0  1994.0  John Wiley &amp; Sons Inc  \n",
       "1  1995.0      John Wiley &amp; Sons  \n",
       "2  1974.0           Thomson Learning  \n",
       "3  1982.0        Henry Holt &amp; Co  \n",
       "4  2002.0                 Avon Books  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge ratings with books\n",
    "ratings_with_books = ratings.merge(books, on='ISBN')\n",
    "print(\"Ratings with books merged DataFrame head:\")\n",
    "ratings_with_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16f10d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487671, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_with_books.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f4043",
   "metadata": {},
   "source": [
    "# Calculate number of ratings per book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7626651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings per book:\n",
      "                                               title  num_of_rating\n",
      "0   A Light in the Storm: The Civil War Diary of ...              2\n",
      "1                              Always Have Popsicles              1\n",
      "2               Apple Magic (The Collector's series)              1\n",
      "3   Beyond IBM: Leadership Marketing and Finance ...              1\n",
      "4   Clifford Visita El Hospital (Clifford El Gran...              1\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of ratings per book\n",
    "number_rating = ratings_with_books.groupby('title')['rating'].count().reset_index()\n",
    "number_rating.rename(columns={'rating': 'num_of_rating'}, inplace=True)\n",
    "print(\"Number of ratings per book:\")\n",
    "print(number_rating.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5593baa6",
   "metadata": {},
   "source": [
    "## Filter books with at least 50 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85131167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final rating DataFrame after filtering (head):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>num_of_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277427</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>277427</td>\n",
       "      <td>0060930535</td>\n",
       "      <td>0</td>\n",
       "      <td>The Poisonwood Bible: A Novel</td>\n",
       "      <td>Barbara Kingsolver</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Perennial</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>277427</td>\n",
       "      <td>0060934417</td>\n",
       "      <td>0</td>\n",
       "      <td>Bel Canto: A Novel</td>\n",
       "      <td>Ann Patchett</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Perennial</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>277427</td>\n",
       "      <td>0061009059</td>\n",
       "      <td>9</td>\n",
       "      <td>One for the Money (Stephanie Plum Novels (Pape...</td>\n",
       "      <td>Janet Evanovich</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>HarperTorch</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>277427</td>\n",
       "      <td>006440188X</td>\n",
       "      <td>0</td>\n",
       "      <td>The Secret Garden</td>\n",
       "      <td>Frances Hodgson Burnett</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>HarperTrophy</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id        ISBN  rating  \\\n",
       "0    277427  002542730X      10   \n",
       "13   277427  0060930535       0   \n",
       "15   277427  0060934417       0   \n",
       "18   277427  0061009059       9   \n",
       "24   277427  006440188X       0   \n",
       "\n",
       "                                                title  \\\n",
       "0   Politically Correct Bedtime Stories: Modern Ta...   \n",
       "13                      The Poisonwood Bible: A Novel   \n",
       "15                                 Bel Canto: A Novel   \n",
       "18  One for the Money (Stephanie Plum Novels (Pape...   \n",
       "24                                  The Secret Garden   \n",
       "\n",
       "                     author    year                  publisher  num_of_rating  \n",
       "0         James Finn Garner  1994.0  John Wiley &amp; Sons Inc             82  \n",
       "13       Barbara Kingsolver  1999.0                  Perennial            133  \n",
       "15             Ann Patchett  2002.0                  Perennial            108  \n",
       "18          Janet Evanovich  1995.0                HarperTorch            108  \n",
       "24  Frances Hodgson Burnett  1998.0               HarperTrophy             79  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter books with at least 50 ratings\n",
    "final_rating = ratings_with_books.merge(number_rating, on='title')\n",
    "final_rating = final_rating[final_rating['num_of_rating'] >= 50]\n",
    "final_rating.drop_duplicates(['user_id', 'title'], inplace=True)\n",
    "print(\"Final rating DataFrame after filtering (head):\")\n",
    "final_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de63d022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of final rating DataFrame\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(59850, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Shape of final rating DataFrame\")\n",
    "final_rating.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7035ff",
   "metadata": {},
   "source": [
    "# Step 3: Encode Entities and Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "644104f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Encoding entities and relations...\n",
      "Encoded user, book, and author IDs:\n",
      "    user_id  user_id_encoded  \\\n",
      "0    277427              884   \n",
      "13   277427              884   \n",
      "15   277427              884   \n",
      "18   277427              884   \n",
      "24   277427              884   \n",
      "\n",
      "                                                title  book_id_encoded  \\\n",
      "0   Politically Correct Bedtime Stories: Modern Ta...              396   \n",
      "13                      The Poisonwood Bible: A Novel              621   \n",
      "15                                 Bel Canto: A Novel               71   \n",
      "18  One for the Money (Stephanie Plum Novels (Pape...              380   \n",
      "24                                  The Secret Garden              642   \n",
      "\n",
      "                     author  author_encoded  \n",
      "0         James Finn Garner             249  \n",
      "13       Barbara Kingsolver              53  \n",
      "15             Ann Patchett              27  \n",
      "18          Janet Evanovich             264  \n",
      "24  Frances Hodgson Burnett             186  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 3: Encoding entities and relations...\")\n",
    "# Encode user_ids, book titles, and authors\n",
    "user_encoder = LabelEncoder()\n",
    "book_encoder = LabelEncoder()\n",
    "author_encoder = LabelEncoder()\n",
    "\n",
    "final_rating['user_id_encoded'] = user_encoder.fit_transform(final_rating['user_id'])\n",
    "final_rating['book_id_encoded'] = book_encoder.fit_transform(final_rating['title'])\n",
    "final_rating['author_encoded'] = author_encoder.fit_transform(final_rating['author'])\n",
    "print(\"Encoded user, book, and author IDs:\")\n",
    "print(final_rating[['user_id', 'user_id_encoded', 'title', 'book_id_encoded', 'author', 'author_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8fda1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 888\n",
      "Number of unique books: 742\n",
      "Number of unique authors: 584\n"
     ]
    }
   ],
   "source": [
    "# Create entity and relation mappings\n",
    "n_users = len(user_encoder.classes_)\n",
    "n_books = len(book_encoder.classes_)\n",
    "n_authors = len(author_encoder.classes_)\n",
    "print(f\"Number of unique users: {n_users}\")\n",
    "print(f\"Number of unique books: {n_books}\")\n",
    "print(f\"Number of unique authors: {n_authors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b82c5a",
   "metadata": {},
   "source": [
    "# Step 4: Build Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7608668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Building knowledge graph...\n",
      "Knowledge graph edge index shape: torch.Size([2, 60592])\n",
      "Knowledge graph edge types shape: torch.Size([60592])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 4: Building knowledge graph...\")\n",
    "# Create user-book interaction edges (relation type: 'rated')\n",
    "kg_edges = []\n",
    "for _, row in final_rating.iterrows():\n",
    "    kg_edges.append((row['user_id_encoded'], row['book_id_encoded'] + n_users, 'rated'))\n",
    "\n",
    "# Add book-author relations\n",
    "for _, row in final_rating.drop_duplicates('title').iterrows():\n",
    "    kg_edges.append((row['book_id_encoded'] + n_users, row['author_encoded'] + n_users + n_books, 'written_by'))\n",
    "\n",
    "# Convert edges to tensor\n",
    "edge_index = []\n",
    "edge_type = []\n",
    "relation_types = {'rated': 0, 'written_by': 1}\n",
    "for src, dst, rel in kg_edges:\n",
    "    edge_index.append([src, dst])\n",
    "    edge_type.append(relation_types[rel])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "edge_type = torch.tensor(edge_type, dtype=torch.long)\n",
    "print(\"Knowledge graph edge index shape:\", edge_index.shape)\n",
    "print(\"Knowledge graph edge types shape:\", edge_type.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797f61ba",
   "metadata": {},
   "source": [
    "# Step 5: Define KGAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6a89af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KGAT Model\n",
    "class KGAT(nn.Module):\n",
    "    def __init__(self, n_entities, n_relations, embed_dim):\n",
    "        super(KGAT, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        # Entity and relation embeddings\n",
    "        self.entity_emb = nn.Embedding(n_entities, embed_dim)\n",
    "        self.relation_emb = nn.Embedding(n_relations, embed_dim)\n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Linear(embed_dim * 2, 1)\n",
    "        self.W = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        nn.init.xavier_normal_(self.entity_emb.weight)\n",
    "        nn.init.xavier_normal_(self.relation_emb.weight)\n",
    "        \n",
    "    def forward(self, edge_index, edge_type):\n",
    "        head = self.entity_emb(edge_index[0])\n",
    "        tail = self.entity_emb(edge_index[1])\n",
    "        rel = self.relation_emb(edge_type)\n",
    "        \n",
    "        # Attention scores\n",
    "        head_rel = torch.cat([head, rel], dim=-1)\n",
    "        att_scores = torch.sigmoid(self.attention(head_rel))\n",
    "        \n",
    "        # Aggregate neighbor embeddings manually\n",
    "        neighbor_emb = att_scores * tail\n",
    "        # Initialize aggregated embeddings\n",
    "        aggr_emb = torch.zeros(self.entity_emb.num_embeddings, self.embed_dim).to(head.device)\n",
    "        # Manually aggregate by summing neighbor embeddings for each head\n",
    "        for i in range(edge_index.shape[1]):\n",
    "            head_idx = edge_index[0, i]\n",
    "            aggr_emb[head_idx] += neighbor_emb[i]\n",
    "        \n",
    "        # Update embeddings\n",
    "        entity_emb = torch.tanh(self.W(aggr_emb))\n",
    "        return entity_emb\n",
    "\n",
    "    def predict(self, user_ids, item_ids):\n",
    "        user_emb = self.entity_emb(user_ids)\n",
    "        item_emb = self.entity_emb(item_ids)\n",
    "        scores = (user_emb * item_emb).sum(dim=-1)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0125b5",
   "metadata": {},
   "source": [
    "# Step 6: Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a5b8a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 6: Setting up training...\n",
      "Training data sample:\n",
      "        user_id_encoded  book_id_encoded  rating\n",
      "14222                24             1338       0\n",
      "28563                28             1252       9\n",
      "473722              856             1253      10\n",
      "203805              346             1081       6\n",
      "56037                83             1315       0\n",
      "\n",
      "Test data sample:\n",
      "        user_id_encoded  book_id_encoded  rating\n",
      "484226              879             1174      10\n",
      "271798              488              951       8\n",
      "66307               101             1626       0\n",
      "335782              607             1599       0\n",
      "430341              769             1435       7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "print(\"\\nStep 6: Setting up training...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_entities = n_users + n_books + n_authors\n",
    "n_relations = len(relation_types)\n",
    "embed_dim = 64\n",
    "model = KGAT(n_entities, n_relations, embed_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "edge_index = edge_index.to(device)\n",
    "edge_type = edge_type.to(device)\n",
    "\n",
    "# Prepare training and test data\n",
    "train_data = final_rating[['user_id_encoded', 'book_id_encoded', 'rating']].copy()\n",
    "train_data['book_id_encoded'] = train_data['book_id_encoded'] + n_users  # Offset book IDs\n",
    "train_data, test_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "print(\"Training data sample:\")\n",
    "print(train_data.head())\n",
    "print(\"\\nTest data sample:\")\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef01be5",
   "metadata": {},
   "source": [
    "# Step 7: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94b2604c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 7: Training KGAT model...\n",
      "Epoch 1, Loss: 16.5146\n",
      "Epoch 2, Loss: 16.5117\n",
      "Epoch 3, Loss: 16.5088\n",
      "Epoch 4, Loss: 16.5059\n",
      "Epoch 5, Loss: 16.5029\n",
      "Epoch 6, Loss: 16.4999\n",
      "Epoch 7, Loss: 16.4969\n",
      "Epoch 8, Loss: 16.4938\n",
      "Epoch 9, Loss: 16.4906\n",
      "Epoch 10, Loss: 16.4874\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"\\nStep 7: Training KGAT model...\")\n",
    "def train(model, edge_index, edge_type, train_data, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        entity_emb = model(edge_index, edge_type)\n",
    "        \n",
    "        # Compute loss\n",
    "        user_ids = torch.tensor(train_data['user_id_encoded'].values, dtype=torch.long).to(device)\n",
    "        item_ids = torch.tensor(train_data['book_id_encoded'].values, dtype=torch.long).to(device)\n",
    "        ratings = torch.tensor(train_data['rating'].values, dtype=torch.float).to(device)\n",
    "        \n",
    "        pred_scores = model.predict(user_ids, item_ids)\n",
    "        loss = F.mse_loss(pred_scores, ratings)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "train(model, edge_index, edge_type, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2831cac",
   "metadata": {},
   "source": [
    " ### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dabd938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model performance...\n",
      "RMSE on test set: 4.1100\n",
      "Precision@5 on test set: 0.2000\n"
     ]
    }
   ],
   "source": [
    "# Performance Evaluation\n",
    "print(\"\\nEvaluating model performance...\")\n",
    "def evaluate_model(model, edge_index, edge_type, test_data, k=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Forward pass to get entity embeddings\n",
    "        entity_emb = model(edge_index, edge_type)\n",
    "        \n",
    "        # Compute predictions for test set\n",
    "        user_ids = torch.tensor(test_data['user_id_encoded'].values, dtype=torch.long).to(device)\n",
    "        item_ids = torch.tensor(test_data['book_id_encoded'].values, dtype=torch.long).to(device)\n",
    "        true_ratings = torch.tensor(test_data['rating'].values, dtype=torch.float).to(device)\n",
    "        \n",
    "        pred_scores = model.predict(user_ids, item_ids)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse = torch.sqrt(F.mse_loss(pred_scores, true_ratings)).item()\n",
    "        print(f\"RMSE on test set: {rmse:.4f}\")\n",
    "        \n",
    "        # Calculate Precision@K\n",
    "        _, top_k_indices = pred_scores.topk(k, dim=0)\n",
    "        top_k_true_ratings = true_ratings[top_k_indices]\n",
    "        relevant_count = (top_k_true_ratings >= 6).sum().item()  # Assuming rating >= 6 is relevant\n",
    "        precision_at_k = relevant_count / k\n",
    "        print(f\"Precision@{k} on test set: {precision_at_k:.4f}\")\n",
    "\n",
    "evaluate_model(model, edge_index, edge_type, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f77f165",
   "metadata": {},
   "source": [
    "# Step 8: Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee8a8c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 8: Defining recommendation function...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 8: Defining recommendation function...\")\n",
    "def recommend_books(user_id, model, book_encoder, n_users, top_k=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            user_id_encoded = user_encoder.transform([user_id])[0]\n",
    "        except ValueError:\n",
    "            print(f\"User ID {user_id} not found in the dataset.\")\n",
    "            return [], []\n",
    "        user_tensor = torch.tensor([user_id_encoded], dtype=torch.long).to(device)\n",
    "        \n",
    "        # Get all book embeddings\n",
    "        book_ids = torch.arange(n_users, n_users + n_books, dtype=torch.long).to(device)\n",
    "        scores = model.predict(user_tensor.expand(len(book_ids)), book_ids)\n",
    "        \n",
    "        # Get top-k book indices\n",
    "        _, top_indices = scores.topk(top_k)\n",
    "        top_book_ids = top_indices.cpu().numpy()\n",
    "        \n",
    "        # Decode book titles\n",
    "        recommended_books = book_encoder.inverse_transform(top_book_ids)\n",
    "        return recommended_books, top_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8968e2a",
   "metadata": {},
   "source": [
    "# Step 9: Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dda1eb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 9: Defining visualization functions...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 9: Defining visualization functions...\")\n",
    "def visualize_recommendations(user_id, recommended_books, top_indices, model, book_encoder, n_users):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        user_id_encoded = user_encoder.transform([user_id])[0]\n",
    "        user_tensor = torch.tensor([user_id_encoded], dtype=torch.long).to(device)\n",
    "        book_ids = torch.arange(n_users, n_users + n_books, dtype=torch.long).to(device)\n",
    "        scores = model.predict(user_tensor.expand(len(book_ids)), book_ids)\n",
    "        top_scores = scores[top_indices].cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(recommended_books, top_scores, color='skyblue')\n",
    "    plt.xlabel('Book Titles')\n",
    "    plt.ylabel('Predicted Score')\n",
    "    plt.title(f'Top-5 Recommended Books for User {user_id}')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('recommendations_bar_chart.png')\n",
    "    plt.close()\n",
    "\n",
    "def visualize_kg_subgraph(user_id, recommended_books, final_rating, book_encoder, user_encoder, author_encoder):\n",
    "    G = nx.DiGraph()\n",
    "    user_id_encoded = user_encoder.transform([user_id])[0]\n",
    "    G.add_node(f\"User_{user_id}\", label=f\"User {user_id}\", type='user')\n",
    "\n",
    "    # Add recommended books and their authors\n",
    "    for book in recommended_books:\n",
    "        book_id_encoded = book_encoder.transform([book])[0]\n",
    "        G.add_node(f\"Book_{book_id_encoded}\", label=book, type='book')\n",
    "        G.add_edge(f\"User_{user_id}\", f\"Book_{book_id_encoded}\", relation='rated')\n",
    "\n",
    "        # Find the author of the book\n",
    "        book_row = final_rating[final_rating['title'] == book].iloc[0]\n",
    "        author_encoded = book_row['author_encoded']\n",
    "        author_name = author_encoder.inverse_transform([author_encoded])[0]\n",
    "        G.add_node(f\"Author_{author_encoded}\", label=author_name, type='author')\n",
    "        G.add_edge(f\"Book_{book_id_encoded}\", f\"Author_{author_encoded}\", relation='written_by')\n",
    "\n",
    "    # Plot the graph\n",
    "    pos = nx.spring_layout(G)\n",
    "    node_colors = ['lightblue' if G.nodes[node]['type'] == 'user' else 'lightgreen' if G.nodes[node]['type'] == 'book' else 'salmon' for node in G.nodes]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    nx.draw(G, pos, with_labels=True, labels=nx.get_node_attributes(G, 'label'), node_color=node_colors, node_size=2000, font_size=10, font_weight='bold')\n",
    "    edge_labels = nx.get_edge_attributes(G, 'relation')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "    plt.title(f'Knowledge Graph Subgraph for User {user_id}')\n",
    "    plt.savefig('kg_subgraph.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a3a6b",
   "metadata": {},
   "source": [
    "# Step 10: Test Recommendations and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ef0a6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 10: Testing recommendations and visualizations...\n",
      "Recommended books for user 11676:\n",
      "1. It\n",
      "2. B Is for Burglar (Kinsey Millhone Mysteries (Paperback))\n",
      "3. Mind Prey\n",
      "4. How to Be Good\n",
      "5. The Phantom Tollbooth\n",
      "Visualizations saved as 'recommendations_bar_chart.png' and 'kg_subgraph.png'.\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Test Recommendations and Visualizations\n",
    "print(\"\\nStep 10: Testing recommendations and visualizations...\")\n",
    "test_user_id = active_users[0]  # Use the first active user for testing\n",
    "recommended_books, top_indices = recommend_books(test_user_id, model, book_encoder, n_users)\n",
    "print(f\"Recommended books for user {test_user_id}:\")\n",
    "for i, book in enumerate(recommended_books, 1):\n",
    "    print(f\"{i}. {book}\")\n",
    "\n",
    "# Generate visualizations\n",
    "visualize_recommendations(test_user_id, recommended_books, top_indices, model, book_encoder, n_users)\n",
    "visualize_kg_subgraph(test_user_id, recommended_books, final_rating, book_encoder, user_encoder, author_encoder)\n",
    "print(\"Visualizations saved as 'recommendations_bar_chart.png' and 'kg_subgraph.png'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591e05d",
   "metadata": {},
   "source": [
    "# Step 11: Save Model and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c98a8dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 11: Saving model and artifacts...\n",
      "Artifacts saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Save Model and Artifacts\n",
    "print(\"\\nStep 11: Saving model and artifacts...\")\n",
    "pickle.dump(model.state_dict(), open('artifacts/kgat_model.pkl', 'wb'))\n",
    "pickle.dump(user_encoder, open('artifacts/user_encoder.pkl', 'wb'))\n",
    "pickle.dump(book_encoder, open('artifacts/book_encoder.pkl', 'wb'))\n",
    "pickle.dump(author_encoder, open('artifacts/author_encoder.pkl', 'wb'))\n",
    "print(\"Artifacts saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7fc64b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
